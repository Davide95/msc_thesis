\chapter{Topic Modeling}

In Chapter \ref{wordemb}, we presented some techniques to encode words as vectors.
Starting from a bag-of-words model in which we assume that the order of the words
inside a document does not matter, it is possible to follow a similar approach also for them.

\section{Latent Semantic Analysis (LSA)}
\dots

\section{Latent Dirichlet Allocation (LDA)}
\dots

\section{Hierarchical Dirichlet Process (HDA)}
\dots