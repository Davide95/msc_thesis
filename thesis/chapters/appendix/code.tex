\chapter{Source code}
All source code is licensed under the GNU General Public License v3.0 and it can be found at \url{https://github.com/Davide95/msc_thesis}.
In order to have a self-contained document, the realized scripts are also inserted in this appendix.
You can find a copy of the license at \url{https://github.com/Davide95/msc_thesis/blob/master/code/LICENSE}.

All code is written in Python 3.7. The external libraries used are reported in the relative \texttt{requirements.txt} file and can be installed through the command \texttt{pip install -r requirements.txt}.

All experiments were tested on a PowerEdge T630 server with the following characteristics:
\begin{itemize}
    \item Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz (2 sockets)
    \item 8x16GiB of RAM
\end{itemize}

\section{Requirements}
\begin{minipage}{\linewidth}
    \lstinputlisting[caption=requirements.txt]{../code/requirements.txt}
\end{minipage}

\section{Spider} \label{spider}

Since the spider implemented is built on top of the web-crawling platform Scrapy, we refer to its documentation instead of explaining how to run it.
An overview of Scrapy can be found in \cite{kouzis2016learning}.

\lstinputlisting[language=Python, caption=custom\_spider.py]{../code/custom_spider.py}

\section{Preprocessing} \label{preprocessing}
The script has to be launched with two mandatory parameters:
\begin{itemize}
    \item input\_folder: the folder in which all scraped data is stored as CSV files
    \item output\_folder: the folder in which to save the preprocessed data. If the folder doesn't exist, it will be created at runtime
\end{itemize}

\lstinputlisting[language=Python, caption=preprocessing.py]{../code/preprocessing.py}